{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import linear_model\n",
    "#import pylab as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###This notebook will focus on the analytical part of the 311 demographics analysis: that is, multilinear regressions between resident and working population socio-demographic attributes and  the number of 311 calls by type per capita, at the census tract level will be performed and analyzed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195 194 194\n"
     ]
    }
   ],
   "source": [
    "#Upload the working population attributes, and the resident population attributes at the CT level. Then, merging both datasets\n",
    "#File with resident demographics\n",
    "demographics_NTA_NYC_residents=pd.read_csv('data/demographics_nta_NYC_residents_compiled.csv').drop(['Unnamed: 0', 'Unnamed: 0.1'],axis=1)\n",
    "#File with working population demographics\n",
    "demographics_NTA_NYC_workers=pd.read_csv('data/demographics_nta_NYC_workers_compiled.csv').drop(['Unnamed: 0', 'Unnamed: 0.1'],axis=1)\n",
    "#Merging both datasets:\n",
    "demographics_NTA_NYC=pd.merge(demographics_NTA_NYC_residents,demographics_NTA_NYC_workers,on='Neighborhood',how='inner')\n",
    "print len(demographics_NTA_NYC_residents),len(demographics_NTA_NYC_workers),len(demographics_NTA_NYC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, 'demographics_NTA_NYC' will be the dataset that combines working and resident populations for each NTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "residents_demographics=demographics_NTA_NYC_residents.columns[2:]\n",
    "workers_demographics=demographics_NTA_NYC_workers.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Upload the 311 calls by type per capita\n",
    "calls_bytype_normalized=pd.read_csv('data/Call by type with normalization by resident - NTA level_v2.csv').drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####The next dataset will combine all the information (demographics + calls by type normalized by resident population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 190 194\n"
     ]
    }
   ],
   "source": [
    "#callsbytype_attributes will be a dataframe combining all the information (demographics + calls by type)\n",
    "callsbytype_attributes=pd.merge(calls_bytype_normalized,demographics_NTA_NYC, on='Neighborhood',how='inner')\n",
    "print len(callsbytype_attributes), len(calls_bytype_normalized),len(demographics_NTA_NYC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list of type of calls that will be the dependent variables in regressions\n",
    "types_of_calls=calls_bytype_normalized.columns[:-3]  #types of calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regressors=[u'Population under 18', u'population between 18 and 34',\n",
    "       u'population between 35 to 64', u'population 65 and over',\n",
    "       u'Population white', u'population black', u'Population asian',\n",
    "       u'population hispanic', u'population other race',\n",
    "       u'family households', u'nonfamily households',\n",
    "       u'population education high school', u'population education bachelors',\n",
    "       u'population education masters', u'population education phd',\n",
    "        u'owner  occupied units',\n",
    "       u'renter occupied units', u'transportation car', u'number of cars',\n",
    "       u'transportation public', u'tranportation motorcycle',\n",
    "        u'household income form 10 to 40',\n",
    "       u'household income form 40 to 75', u'household income 75 and above',\n",
    "       u'house value for 20 to 100', u'house value for 100 to 500',\n",
    "       u'house value 500 or more', u'rent bewteen 300 and 1000',\n",
    "       u'rent bewteen 1000 and 2000', u'rent 2000 or more',\n",
    "       u'Transportation Other means', u'population between 18 and 34_n',\n",
    "       u'population between 35 to 64_n', u'population 65 and over_n',\n",
    "       u'Population white_n', u'population black_n', u'Population asian_n',\n",
    "       u'population hispanic_n', u'population other _n',\n",
    "       u'family households_n', u'nonfamily households_n',\n",
    "       u'population education high school_n',\n",
    "       u'population education bachelors_n', u'population education masters_n',\n",
    "       u'population education phd_n', u'household income less than 10_n',\n",
    "       u'owner  occupied units_n', u'renter occupied units_n',\n",
    "       u'transportation car_n', u'transportation public_n',\n",
    "       u'tranportation motorcycle_n', \n",
    "       u'household income form 10 to 40_n',\n",
    "       u'household income form 40 to 75_n', u'household income 75 and above_n',\n",
    "       u'house value for 20 to 100_n', u'house value for 100 to 500_n',\n",
    "       u'house value 500 or more_n', u'rent bewteen 300 and 1000_n',\n",
    "       u'rent bewteen 1000 and 2000_n', u'Transportation Other means_n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets Consider different groups of population $g=1,2,â€¦,n$ (based on our demographic indicators) and let:\n",
    "\n",
    "\n",
    "$Pr(a,g)$ - the total number of residents in the location $a$ of group $g$ \n",
    "\n",
    "while $Pc(a,g)$ the number of commuters.\n",
    " \n",
    "Let the unknown (subject to fit) complaining behavior be defined by the average number of complains of type $t$ per resident of group $g$ within his/her place of residency be $rc(g,t)$\n",
    "\n",
    "Let also, $wc(g,t)$ be the number of complains of type $t$ per commuter of type $g$.\n",
    "\n",
    "Then the total observed number of complains of type $t$ in the area $a$ is:\n",
    "\n",
    "$$C(a,t)=\\sum_{g,t} Pr(a,g) \\ rc(g,t) + \\sum_{g,t} Pc(a,g) \\ wc(g,t) \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\  \\text{(1)}$$ \n",
    "\n",
    "Then we know $Pr(a,g)$ and $Pc(a,g)$ (those are our regressors), we know the output variable $C(a,t)$ from 311 statistics. We need to fit the $rc(g,t)$, $wc(g,t)$ - slope coefficients of the multivariate linear regression.\n",
    "\n",
    "This will give us complaining behavior per people of different groups and it will be distinguished by the complaining mode - while at home and while on the way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###we will procced as follows:\n",
    "\n",
    "STEP 1) Lasso regression:\n",
    "\n",
    "Regressors:  \n",
    "\n",
    "$Pr(a,g)$ - the total number of residents in the location $a$ of group $g$.\n",
    "            \n",
    "$Pc(a,g)$  number of commuters in the location a of group $g$\n",
    "\n",
    "Target variable to be fit: $rc(g,t)$ -   average number of complains of type $t$ per resident of group $g$                                                      within his/her place of residency \n",
    "\n",
    "STEP 2) predict the number of complains per capita $wc(g,t)$ from the results of step 1, using equation $(1)$\n",
    "\n",
    "Using the predicted value $rc(g,t)$ in each area, we are able to get a $wc(g,t)$ prediction (from the formula of the observed total calls by type $C(a,t)$ variable) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next piece of code will prepare the datasets for the regressions: X the dataframe combining all the regressors, Y a column of the number of calls normalized.\n",
    "The variable \"typeof\" is the type of call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise\n"
     ]
    }
   ],
   "source": [
    "typeof= 'Noise'\n",
    "print typeof\n",
    "A2=np.append(np.append(regressors,typeof),'Neighborhood')   #selection of columns\n",
    "myframe1=callsbytype_attributes[A2].dropna() \n",
    "X=myframe1[regressors]\n",
    "Y=myframe1[typeof]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parameters for random forest\n",
    "max_features = ['auto','sqrt','log2']\n",
    "criterion = ['gini','entropy']\n",
    "n_estimators = [100,500,1000,5000]\n",
    "import itertools\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The code will just run if the type of complain is present in more than 50 NTA.\n",
    "if len(myframe1)>50:\n",
    "    #Divide the datasets in train, validation and test sets\n",
    "    X_pre_train, X_test, label_pre_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=1)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_pre_train, label_pre_train, test_size=0.25, random_state=1)\n",
    "    d=[]\n",
    "    for mf,n_estim in itertools.product(max_features,n_estimators):\n",
    "        forest=RandomForestRegressor(n_estimators=n_estim, max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "         min_weight_fraction_leaf=0.0, max_features=mf,\n",
    "         max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False)\n",
    "        forest.fit(X_train,Y_train)\n",
    "        forest_pred = forest.predict(X_val)\n",
    "        name = '%s,%s'%(str(mf),str(n_estim))\n",
    "        d.append((name,r2_score(Y_val,forest_pred)))\n",
    "    #Take the best R2 over the validation set for selecting the \n",
    "    best_solution=sorted(d, key=lambda tup: tup[1])[-1]\n",
    "    parameters= best_solution[0].split(',')    \n",
    "    mf=parameters[0]\n",
    "    n_estim=parameters[1]\n",
    "    #Run the regression again with the selected parameters o\n",
    "    forest=RandomForestRegressor(n_estimators=int(n_estim), max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "         min_weight_fraction_leaf=0.0, max_features=mf,\n",
    "         max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False)\n",
    "    forest.fit(X_train,Y_train)\n",
    "    features_scores_list=sorted(zip(map(lambda x: round(x, 4), forest.feature_importances_), regressors), \n",
    "             reverse=True)\n",
    "    features_scores_table=pd.DataFrame(features_scores_list, columns=['slope_coeff', 'variable'])\n",
    "    features_scores_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The same previous code but for all the types of complains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results={}\n",
    "for typeof in types_of_calls:\n",
    "    A2=np.append(np.append(regressors,typeof),'Neighborhood')   #selection of columns\n",
    "    myframe1=callsbytype_attributes[A2].dropna() \n",
    "    if len(myframe1)>50:\n",
    "        results[typeof]={}\n",
    "        X=myframe1[regressors]\n",
    "        Y=myframe1[typeof]\n",
    "        #Random Forest \n",
    "        X_pre_train, X_test, label_pre_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=1)\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X_pre_train, label_pre_train, test_size=0.25, random_state=1)\n",
    "        d=[]\n",
    "        for mf,n_estim in itertools.product(max_features,n_estimators):\n",
    "            forest=RandomForestRegressor(n_estimators=n_estim, max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "             min_weight_fraction_leaf=0.0, max_features=mf,\n",
    "             max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False)\n",
    "            forest.fit(X_train,Y_train)\n",
    "            forest_pred = forest.predict(X_val)\n",
    "            name = '%s,%s'%(str(mf),str(n_estim))\n",
    "            d.append((name,r2_score(Y_val,forest_pred)))\n",
    "        best_solution=sorted(d, key=lambda tup: tup[1])[-1]\n",
    "        parameters=best_solution[0].split(',')      \n",
    "        mf=parameters[0]\n",
    "        n_estim=parameters[1]\n",
    "        forest=RandomForestRegressor(n_estimators=int(n_estim), max_depth=None, min_samples_split=2, min_samples_leaf=1,\n",
    "         min_weight_fraction_leaf=0.0, max_features=mf,\n",
    "         max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, random_state=None, verbose=0, warm_start=False)\n",
    "        forest.fit(X_train,Y_train)\n",
    "        results[typeof]['sample']=len(myframe1)\n",
    "        ##############for getting a table with coefficients sorted by importance\n",
    "        features_scores_list=sorted(zip(map(lambda x: round(x, 4), forest.feature_importances_), regressors), \n",
    "             reverse=True)\n",
    "        results[typeof]['features']=pd.DataFrame(features_scores_list, columns=['slope_coeff', 'variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the results are stored in the outputs folder, they can be seen at:\n",
    "results_random_forest=pd.read_csv('outputs/rf_results_NTA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
